[["index.html", "R을 이용한 데이터 분석 시작하기 R 패키지 목록", " R을 이용한 데이터 분석 PARK Yeonkyu 2022-03-12 시작하기 실무 경험을 바탕으로 R을 이용한 통계분석과 기계학습 내용을 담고 있다. R 패키지 목록 예제에서 사용한 패키지 목록이다. ## [1] &quot;R-base&quot; "],["데이터-탐색.html", "1 데이터 탐색 1.1 데이터 적재 1.2 데이터 훑어보기 1.3 집단별 정보 요약", " 1 데이터 탐색 EDA(Exploratory Data Analysis), 탐색적 데이터 분석은 수집된 데이터를 전체적으로 살펴보는 과정이다. 1.1 데이터 적재 1.2 데이터 훑어보기 1.3 집단별 정보 요약 "],["데이터-전처리.html", "2 데이터 전처리 2.1 결측치 처리", " 2 데이터 전처리 2.1 결측치 처리 결측치는 관측된 표본에서 누락된 값을 의미한다. 관측치의 종류에서 다음과 같다. 결측치 종류 2.1.1 결측치 확인 결측치를 확인하는 방법은 여러가지가 있으나 is.na() 함수나 summary() 함수를 통해 가능하다. summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 colSums(is.na(penguins)) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex year ## 2 2 11 0 VIM 패키지 aggr() 함수를 사용하면 결측치를 시각화 할 수 있다. aggr(penguins, prop=F, numbers=T) marginplot(penguins[c(3:4)], pch=20, col=c(&quot;darkgray&quot;, &quot;red&quot;, &quot;blue&quot;)) mice 패키지 md.pattern() 함수를 이용해서도 결측치를 확인할 수 있다. md.pattern(penguins, plot = T, rotate.names = T) ## species island year bill_length_mm bill_depth_mm flipper_length_mm ## 333 1 1 1 1 1 1 ## 9 1 1 1 1 1 1 ## 2 1 1 1 0 0 0 ## 0 0 0 2 2 2 ## body_mass_g sex ## 333 1 1 0 ## 9 1 0 1 ## 2 0 0 5 ## 2 11 19 2.1.2 결측치 제거 결측치가 변수가 영향이 없고 표본 크기가 충분히 크다면 간단히 제거함으로써 데이터를 정제할 수 있다. penguins.naomit1 &lt;- na.omit(penguins); penguins.naomit2 &lt;- na.omit(penguins); rbind(penguins.naomit1 = colSums(is.na(penguins.naomit1)), penguins.naomit2 = colSums(is.na(penguins.naomit2))) ## species island bill_length_mm bill_depth_mm flipper_length_mm ## penguins.naomit1 0 0 0 0 0 ## penguins.naomit2 0 0 0 0 0 ## body_mass_g sex year ## penguins.naomit1 0 0 0 ## penguins.naomit2 0 0 0 2.1.3 결측치 대체 2.1.3.1 단순 대체 결측치를 하나의 값(0, 평균/중앙값 등)으로 대체하는 방법이다. 이 방법은 무작위적이지 않기 때문에 무작위 오차가 발생하지 않는다. 즉 누락된 데이터의 양이 많을수록 표준오차가 과소평가되고 변수들간의 상관관계에 영향을 주어 부정확한 p값을 산출하게 된다. 2.1.3.1.1 NA값을 제거하고 평균 계산 p &lt;- penguins[c(3:6)] colMeans(p, na.rm = T) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.92193 17.15117 200.91520 4201.75439 2.1.3.1.2 0으로 대체 p.0 &lt;- penguins[c(3:6)] for(i in colnames(p.0)) { p.0[is.na(p.0[,i]), i] &lt;- 0 } colMeans(p.0) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.66657 17.05145 199.74709 4177.32558 2.1.3.1.3 평균으로 대체 p.mean &lt;- as.data.frame(penguins[c(3:6)]) all_column_mean &lt;- apply(p.mean, 2, mean, na.rm=T) for(i in colnames(p.mean)) { p.mean[is.na(p.mean[,i]), i] &lt;- all_column_mean[i] } colMeans(p.mean) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.92193 17.15117 200.91520 4201.75439 2.1.3.2 다중 대체 시뮬레이션을 통해 제시된 최적의 해로 대체한다. MICE와 `Amelia가 다중 대체법을 지원하는 대표적인 패키지이다. p.mice &lt;- mice(penguins, m=1) ## ## iter imp variable ## 1 1 bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex ## 2 1 bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex ## 3 1 bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex ## 4 1 bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex ## 5 1 bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex p.mice.complete &lt;- complete(p.mice,1) 제거/대체를 통해 데이터 정제한 평균값 비교 rbind( P.orig = colMeans(p, na.rm = T), P.zero = colMeans(p.0), P.mean = colMeans(p.mean), p.mice = colMeans(p.mice.complete[c(3:6)]) ) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## P.orig 43.92193 17.15117 200.9152 4201.754 ## P.zero 43.66657 17.05145 199.7471 4177.326 ## P.mean 43.92193 17.15117 200.9152 4201.754 ## p.mice 43.91890 17.15000 200.9186 4201.163 "],["데이터-시각화.html", "3 데이터 시각화", " 3 데이터 시각화 "],["시각화.html", "4 시각화 4.1 확률분포 그래프 그리기", " 4 시각화 4.1 확률분포 그래프 그리기 dnorm_range &lt;- function(x) { y &lt;- dnorm(x) y[x &lt; -1.96 | x &gt; 1.96] &lt;- NA return(y) } ggplot(data = data.frame(x = c(-3, 3)), aes(x)) + stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1)) + stat_function(fun=dnorm_range, geom=&quot;area&quot;, fill=&quot;grey&quot;, alpha = .5) + geom_vline(xintercept = c(-1.96, 1.96), col=&quot;blue&quot;, linetype=&quot;dashed&quot;) + geom_text(x=c(-1.96-0.2, 1.96+0.2), y=0.08, aes(label = c(&quot;-1.96&quot;, &quot;1.96&quot;)), col=&quot;blue&quot;) + geom_text(x=0, y=0.1, aes(label = &quot;95%&quot;), col=&quot;darkgray&quot;) + labs(title = &quot;Normal Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + theme_bw() "],["데이터-검정.html", "5 데이터 검정 5.1 정규성 검정", " 5 데이터 검정 5.1 정규성 검정 정규분포를 따른 통계분석 기법을 사용하기 위해서는 표본의 정규성 여부를 확인해야 한다. 정규성 검정은 shapiro.test() 함수나 qqnorm() 함수를 통해 확인할 수 있다. set.seed(123) sample &lt;- rnorm(100, mean=100, sd=10) # 정규분포 상의 표본 생성 shapiro.test(sample) ## ## Shapiro-Wilk normality test ## ## data: sample ## W = 0.99388, p-value = 0.9349 Shapiro-Wilk 정규성 검정은 주어진 표본이 정규성을 따른다는 귀무가설을 검정한다. p값이 0.9349으로 귀무가설을 채택한다. 즉 주어진 표본은 정규성을 따른다고 판단된다. qqnorm() 함수와 qqline() 함수는 정규성 여부를 시각화 한다. qqnorm(sample, col=&quot;blue&quot;, main = &quot;Sample from Normal Distribution&quot;) qqline(sample) 참고로 일양분포(uniform distribution)로 생성된 표본의 경우 정규성 검정 결과는 다음과 같다. set.seed(123) sample_uni &lt;- runif(100, min=2, max=4) shapiro.test(sample_uni) ## ## Shapiro-Wilk normality test ## ## data: sample_uni ## W = 0.95237, p-value = 0.001192 p값이 0.0012로 귀무가설을 기각한다. 즉 주어진 표본은 정규성을 따른다고 판단할 수 없다. qqnorm(sample_uni, col=&quot;red&quot;, main = &quot;Sample from Uniform Distribution&quot;) qqline(sample_uni) "],["caret-package.html", "6 caret package 6.1 전처리 6.2 데이터 분할 6.3 모델 학습 6.4 병렬처리 및 하이퍼 파라메터 6.5 Recipes 6.6 성능평가", " 6 caret package The caret Package1 The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models. The package contains tools for: data splitting pre-processing feature selection model tuning using resampling variable importance estimation 6.1 전처리 if(!require(caret)) { install.packages(&quot;caret&quot;) library(caret) } ## ## There is a binary version available but the source version is later: ## binary source needs_compilation ## caret 6.0-90 6.0-91 TRUE ## ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpgUFli8/downloaded_packages if(!require(dplyr)) { install.packages(&quot;dplyr&quot;) library(dplyr) } if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;) library(palmerpenguins) } 6.1.1 Creating Dummy Variables str(penguins) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... 더미변수는 model.matrix() 함수와 dummyVars() 함수를 통해 변환할 수 있다. model.matrix(species ~ ., penguins) %&gt;% head ## (Intercept) islandDream islandTorgersen bill_length_mm bill_depth_mm ## 1 1 0 1 39.1 18.7 ## 2 1 0 1 39.5 17.4 ## 3 1 0 1 40.3 18.0 ## 5 1 0 1 36.7 19.3 ## 6 1 0 1 39.3 20.6 ## 7 1 0 1 38.9 17.8 ## flipper_length_mm body_mass_g sexmale year ## 1 181 3750 1 2007 ## 2 186 3800 0 2007 ## 3 195 3250 0 2007 ## 5 193 3450 0 2007 ## 6 190 3650 1 2007 ## 7 181 3625 0 2007 dummies &lt;- dummyVars(species ~ ., data = penguins) predict(dummies, penguins) %&gt;% head ## island.Biscoe island.Dream island.Torgersen bill_length_mm bill_depth_mm ## 1 0 0 1 39.1 18.7 ## 2 0 0 1 39.5 17.4 ## 3 0 0 1 40.3 18.0 ## 4 0 0 1 NA NA ## 5 0 0 1 36.7 19.3 ## 6 0 0 1 39.3 20.6 ## flipper_length_mm body_mass_g sex.female sex.male year ## 1 181 3750 0 1 2007 ## 2 186 3800 1 0 2007 ## 3 195 3250 1 0 2007 ## 4 NA NA NA NA 2007 ## 5 193 3450 1 0 2007 ## 6 190 3650 0 1 2007 6.1.2 Zero- and Near Zero-Variance Predictors nearZeroVar(penguins, saveMetrics = T) ## freqRatio percentUnique zeroVar nzv ## species 1.225806 0.8720930 FALSE FALSE ## island 1.354839 0.8720930 FALSE FALSE ## bill_length_mm 1.166667 47.6744186 FALSE FALSE ## bill_depth_mm 1.200000 23.2558140 FALSE FALSE ## flipper_length_mm 1.294118 15.9883721 FALSE FALSE ## body_mass_g 1.090909 27.3255814 FALSE FALSE ## sex 1.018182 0.5813953 FALSE FALSE ## year 1.052632 0.8720930 FALSE FALSE data(mdrr) nzv &lt;- nearZeroVar(mdrrDescr, saveMetrics = T); nzv[nzv$nzv,][1:10,] ## freqRatio percentUnique zeroVar nzv ## nTB 23.00000 0.3787879 FALSE TRUE ## nBR 131.00000 0.3787879 FALSE TRUE ## nI 527.00000 0.3787879 FALSE TRUE ## nR03 527.00000 0.3787879 FALSE TRUE ## nR08 527.00000 0.3787879 FALSE TRUE ## nR11 21.78261 0.5681818 FALSE TRUE ## nR12 57.66667 0.3787879 FALSE TRUE ## D.Dr03 527.00000 0.3787879 FALSE TRUE ## D.Dr07 123.50000 5.8712121 FALSE TRUE ## D.Dr08 527.00000 0.3787879 FALSE TRUE nzv &lt;- nearZeroVar(mdrrDescr) filteredDescr &lt;- mdrrDescr[, -nzv] 6.1.3 Identifying Correlated Predictors descrCor &lt;- cor(filteredDescr) highCorr &lt;- sum(abs(descrCor[upper.tri(descrCor)]) &gt; .999) summary(descrCor[upper.tri(descrCor)]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -0.99607 -0.05373 0.25006 0.26078 0.65527 1.00000 highlyCorDescr &lt;- findCorrelation(descrCor, cutoff = .75) filteredDescr &lt;- filteredDescr[,-highlyCorDescr] descrCor2 &lt;- cor(filteredDescr) summary(descrCor2[upper.tri(descrCor2)]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -0.70728 -0.05378 0.04418 0.06692 0.18858 0.74458 6.1.4 Linear Dependencies ltfrDesign &lt;- matrix(0, nrow=6, ncol=6) ltfrDesign[,1] &lt;- c(1, 1, 1, 1, 1, 1) ltfrDesign[,2] &lt;- c(1, 1, 1, 0, 0, 0) ltfrDesign[,3] &lt;- c(0, 0, 0, 1, 1, 1) ltfrDesign[,4] &lt;- c(1, 0, 0, 1, 0, 0) ltfrDesign[,5] &lt;- c(0, 1, 0, 0, 1, 0) ltfrDesign[,6] &lt;- c(0, 0, 1, 0, 0, 1) comboInfo &lt;- findLinearCombos(ltfrDesign); comboInfo ## $linearCombos ## $linearCombos[[1]] ## [1] 3 1 2 ## ## $linearCombos[[2]] ## [1] 6 1 4 5 ## ## ## $remove ## [1] 3 6 ltfrDesign[, -comboInfo$remove] ## [,1] [,2] [,3] [,4] ## [1,] 1 1 1 0 ## [2,] 1 1 0 1 ## [3,] 1 1 0 0 ## [4,] 1 0 1 0 ## [5,] 1 0 0 1 ## [6,] 1 0 0 0 6.1.5 The preProcess Function 데이터 전처리 함수, train() 함수 수행 시 데이터와 I/F를 제공한다. 6.1.6 Centering and Scaling set.seed(96) inTrain &lt;- sample(seq(along=mdrrClass), length(mdrrClass)/2) training &lt;- filteredDescr[inTrain,] test &lt;- filteredDescr[-inTrain,] trainMDRR &lt;- mdrrClass[inTrain] testMDRR &lt;- mdrrClass[-inTrain] preProcValues &lt;- preProcess(training, method = c(&quot;center&quot;, &quot;scale&quot;)) trainTransformed &lt;- predict(preProcValues, training) testTransformed &lt;- predict(preProcValues, test) 6.1.7 Imputation 6.1.8 Transforming Predictors 6.1.9 Putting It All Together if(!require(AppliedPredictiveModeling)) { install.packages(&quot;AppliedPredictiveModeling&quot;) library(AppliedPredictiveModeling) } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpgUFli8/downloaded_packages data(&quot;schedulingData&quot;) str(schedulingData) ## &#39;data.frame&#39;: 4331 obs. of 8 variables: ## $ Protocol : Factor w/ 14 levels &quot;A&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,..: 4 4 4 4 4 4 4 4 4 4 ... ## $ Compounds : num 997 97 101 93 100 100 105 98 101 95 ... ## $ InputFields: num 137 103 75 76 82 82 88 95 91 92 ... ## $ Iterations : num 20 20 10 20 20 20 20 20 20 20 ... ## $ NumPending : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Hour : num 14 13.8 13.8 10.1 10.4 ... ## $ Day : Factor w/ 7 levels &quot;Mon&quot;,&quot;Tue&quot;,&quot;Wed&quot;,..: 2 2 4 5 5 3 5 5 5 3 ... ## $ Class : Factor w/ 4 levels &quot;VF&quot;,&quot;F&quot;,&quot;M&quot;,&quot;L&quot;: 2 1 1 1 1 1 1 1 1 1 ... pp_hpc &lt;- preProcess(schedulingData[, -8], method = c(&quot;center&quot;, &quot;scale&quot;, &quot;YeoJohnson&quot;)); pp_hpc; ## Created from 4331 samples and 7 variables ## ## Pre-processing: ## - centered (5) ## - ignored (2) ## - scaled (5) ## - Yeo-Johnson transformation (5) ## ## Lambda estimates for Yeo-Johnson transformation: ## -0.08, -0.03, -1.05, -1.1, 1.44 transformed &lt;- predict(pp_hpc, schedulingData[, -8]) head(transformed) ## Protocol Compounds InputFields Iterations NumPending Hour Day ## 1 E 1.2289592 -0.6324580 -0.0615593 -0.554123 0.004586516 Tue ## 2 E -0.6065826 -0.8120473 -0.0615593 -0.554123 -0.043733201 Tue ## 3 E -0.5719534 -1.0131504 -2.7894869 -0.554123 -0.034967177 Thu ## 4 E -0.6427737 -1.0047277 -0.0615593 -0.554123 -0.964170752 Fri ## 5 E -0.5804713 -0.9564504 -0.0615593 -0.554123 -0.902085020 Fri ## 6 E -0.5804713 -0.9564504 -0.0615593 -0.554123 0.698108782 Wed mean(schedulingData$NumPending == 0) ## [1] 0.7561764 pp_no_nzv &lt;- preProcess(schedulingData[, -8], method = c(&quot;center&quot;, &quot;scale&quot;, &quot;YeoJohnson&quot;, &quot;nzv&quot;)); pp_no_nzv ## Created from 4331 samples and 7 variables ## ## Pre-processing: ## - centered (4) ## - ignored (2) ## - removed (1) ## - scaled (4) ## - Yeo-Johnson transformation (4) ## ## Lambda estimates for Yeo-Johnson transformation: ## -0.08, -0.03, -1.05, 1.44 pp_no_nzv$method ## $center ## [1] &quot;Compounds&quot; &quot;InputFields&quot; &quot;Iterations&quot; &quot;Hour&quot; ## ## $scale ## [1] &quot;Compounds&quot; &quot;InputFields&quot; &quot;Iterations&quot; &quot;Hour&quot; ## ## $YeoJohnson ## [1] &quot;Compounds&quot; &quot;InputFields&quot; &quot;Iterations&quot; &quot;Hour&quot; ## ## $ignore ## [1] &quot;Protocol&quot; &quot;Day&quot; ## ## $remove ## [1] &quot;NumPending&quot; predict(pp_no_nzv, newdata = schedulingData[1:6, -8]) ## Protocol Compounds InputFields Iterations Hour Day ## 1 E 1.2289592 -0.6324580 -0.0615593 0.004586516 Tue ## 2 E -0.6065826 -0.8120473 -0.0615593 -0.043733201 Tue ## 3 E -0.5719534 -1.0131504 -2.7894869 -0.034967177 Thu ## 4 E -0.6427737 -1.0047277 -0.0615593 -0.964170752 Fri ## 5 E -0.5804713 -0.9564504 -0.0615593 -0.902085020 Fri ## 6 E -0.5804713 -0.9564504 -0.0615593 0.698108782 Wed 6.1.10 Class Distance Calculations 6.2 데이터 분할 6.3 모델 학습 6.4 병렬처리 및 하이퍼 파라메터 6.5 Recipes 6.6 성능평가 https://topepo.github.io/caret/↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
